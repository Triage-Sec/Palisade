// Code generated by protoc-gen-go. DO NOT EDIT.
// versions:
// 	protoc-gen-go v1.36.11
// 	protoc        v6.33.4
// source: prompt_guard/v1/prompt_guard.proto

package promptguardv1

import (
	protoreflect "google.golang.org/protobuf/reflect/protoreflect"
	protoimpl "google.golang.org/protobuf/runtime/protoimpl"
	reflect "reflect"
	sync "sync"
	unsafe "unsafe"
)

const (
	// Verify that this generated code is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(20 - protoimpl.MinVersion)
	// Verify that runtime/protoimpl is sufficiently up-to-date.
	_ = protoimpl.EnforceVersion(protoimpl.MaxVersion - 20)
)

type ClassifyRequest struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The text to classify for prompt injection.
	Text          string `protobuf:"bytes,1,opt,name=text,proto3" json:"text,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ClassifyRequest) Reset() {
	*x = ClassifyRequest{}
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[0]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ClassifyRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ClassifyRequest) ProtoMessage() {}

func (x *ClassifyRequest) ProtoReflect() protoreflect.Message {
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[0]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ClassifyRequest.ProtoReflect.Descriptor instead.
func (*ClassifyRequest) Descriptor() ([]byte, []int) {
	return file_prompt_guard_v1_prompt_guard_proto_rawDescGZIP(), []int{0}
}

func (x *ClassifyRequest) GetText() string {
	if x != nil {
		return x.Text
	}
	return ""
}

type ClassifyResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// The classification label (e.g., "INJECTION", "SAFE").
	Label string `protobuf:"bytes,1,opt,name=label,proto3" json:"label,omitempty"`
	// Confidence score (0.0 to 1.0).
	Confidence float32 `protobuf:"fixed32,2,opt,name=confidence,proto3" json:"confidence,omitempty"`
	// Model inference latency in milliseconds.
	LatencyMs float32 `protobuf:"fixed32,3,opt,name=latency_ms,json=latencyMs,proto3" json:"latency_ms,omitempty"`
	// Model name used for this classification.
	ModelName     string `protobuf:"bytes,4,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ClassifyResponse) Reset() {
	*x = ClassifyResponse{}
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[1]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ClassifyResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ClassifyResponse) ProtoMessage() {}

func (x *ClassifyResponse) ProtoReflect() protoreflect.Message {
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[1]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ClassifyResponse.ProtoReflect.Descriptor instead.
func (*ClassifyResponse) Descriptor() ([]byte, []int) {
	return file_prompt_guard_v1_prompt_guard_proto_rawDescGZIP(), []int{1}
}

func (x *ClassifyResponse) GetLabel() string {
	if x != nil {
		return x.Label
	}
	return ""
}

func (x *ClassifyResponse) GetConfidence() float32 {
	if x != nil {
		return x.Confidence
	}
	return 0
}

func (x *ClassifyResponse) GetLatencyMs() float32 {
	if x != nil {
		return x.LatencyMs
	}
	return 0
}

func (x *ClassifyResponse) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

type ClassifyBatchRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Texts         []string               `protobuf:"bytes,1,rep,name=texts,proto3" json:"texts,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ClassifyBatchRequest) Reset() {
	*x = ClassifyBatchRequest{}
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[2]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ClassifyBatchRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ClassifyBatchRequest) ProtoMessage() {}

func (x *ClassifyBatchRequest) ProtoReflect() protoreflect.Message {
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[2]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ClassifyBatchRequest.ProtoReflect.Descriptor instead.
func (*ClassifyBatchRequest) Descriptor() ([]byte, []int) {
	return file_prompt_guard_v1_prompt_guard_proto_rawDescGZIP(), []int{2}
}

func (x *ClassifyBatchRequest) GetTexts() []string {
	if x != nil {
		return x.Texts
	}
	return nil
}

type ClassifyBatchResponse struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	Results       []*ClassifyResponse    `protobuf:"bytes,1,rep,name=results,proto3" json:"results,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ClassifyBatchResponse) Reset() {
	*x = ClassifyBatchResponse{}
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[3]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ClassifyBatchResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ClassifyBatchResponse) ProtoMessage() {}

func (x *ClassifyBatchResponse) ProtoReflect() protoreflect.Message {
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[3]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ClassifyBatchResponse.ProtoReflect.Descriptor instead.
func (*ClassifyBatchResponse) Descriptor() ([]byte, []int) {
	return file_prompt_guard_v1_prompt_guard_proto_rawDescGZIP(), []int{3}
}

func (x *ClassifyBatchResponse) GetResults() []*ClassifyResponse {
	if x != nil {
		return x.Results
	}
	return nil
}

type ModelInfoRequest struct {
	state         protoimpl.MessageState `protogen:"open.v1"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelInfoRequest) Reset() {
	*x = ModelInfoRequest{}
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[4]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelInfoRequest) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelInfoRequest) ProtoMessage() {}

func (x *ModelInfoRequest) ProtoReflect() protoreflect.Message {
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[4]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelInfoRequest.ProtoReflect.Descriptor instead.
func (*ModelInfoRequest) Descriptor() ([]byte, []int) {
	return file_prompt_guard_v1_prompt_guard_proto_rawDescGZIP(), []int{4}
}

type ModelInfoResponse struct {
	state protoimpl.MessageState `protogen:"open.v1"`
	// Model name (e.g., "protectai/deberta-v3-base-prompt-injection-v2").
	ModelName string `protobuf:"bytes,1,opt,name=model_name,json=modelName,proto3" json:"model_name,omitempty"`
	// Whether the model is loaded and ready.
	Ready bool `protobuf:"varint,2,opt,name=ready,proto3" json:"ready,omitempty"`
	// Device the model is running on (e.g., "cuda", "cpu").
	Device        string `protobuf:"bytes,3,opt,name=device,proto3" json:"device,omitempty"`
	unknownFields protoimpl.UnknownFields
	sizeCache     protoimpl.SizeCache
}

func (x *ModelInfoResponse) Reset() {
	*x = ModelInfoResponse{}
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[5]
	ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
	ms.StoreMessageInfo(mi)
}

func (x *ModelInfoResponse) String() string {
	return protoimpl.X.MessageStringOf(x)
}

func (*ModelInfoResponse) ProtoMessage() {}

func (x *ModelInfoResponse) ProtoReflect() protoreflect.Message {
	mi := &file_prompt_guard_v1_prompt_guard_proto_msgTypes[5]
	if x != nil {
		ms := protoimpl.X.MessageStateOf(protoimpl.Pointer(x))
		if ms.LoadMessageInfo() == nil {
			ms.StoreMessageInfo(mi)
		}
		return ms
	}
	return mi.MessageOf(x)
}

// Deprecated: Use ModelInfoResponse.ProtoReflect.Descriptor instead.
func (*ModelInfoResponse) Descriptor() ([]byte, []int) {
	return file_prompt_guard_v1_prompt_guard_proto_rawDescGZIP(), []int{5}
}

func (x *ModelInfoResponse) GetModelName() string {
	if x != nil {
		return x.ModelName
	}
	return ""
}

func (x *ModelInfoResponse) GetReady() bool {
	if x != nil {
		return x.Ready
	}
	return false
}

func (x *ModelInfoResponse) GetDevice() string {
	if x != nil {
		return x.Device
	}
	return ""
}

var File_prompt_guard_v1_prompt_guard_proto protoreflect.FileDescriptor

const file_prompt_guard_v1_prompt_guard_proto_rawDesc = "" +
	"\n" +
	"\"prompt_guard/v1/prompt_guard.proto\x12\x16triage.prompt_guard.v1\"%\n" +
	"\x0fClassifyRequest\x12\x12\n" +
	"\x04text\x18\x01 \x01(\tR\x04text\"\x86\x01\n" +
	"\x10ClassifyResponse\x12\x14\n" +
	"\x05label\x18\x01 \x01(\tR\x05label\x12\x1e\n" +
	"\n" +
	"confidence\x18\x02 \x01(\x02R\n" +
	"confidence\x12\x1d\n" +
	"\n" +
	"latency_ms\x18\x03 \x01(\x02R\tlatencyMs\x12\x1d\n" +
	"\n" +
	"model_name\x18\x04 \x01(\tR\tmodelName\",\n" +
	"\x14ClassifyBatchRequest\x12\x14\n" +
	"\x05texts\x18\x01 \x03(\tR\x05texts\"[\n" +
	"\x15ClassifyBatchResponse\x12B\n" +
	"\aresults\x18\x01 \x03(\v2(.triage.prompt_guard.v1.ClassifyResponseR\aresults\"\x12\n" +
	"\x10ModelInfoRequest\"`\n" +
	"\x11ModelInfoResponse\x12\x1d\n" +
	"\n" +
	"model_name\x18\x01 \x01(\tR\tmodelName\x12\x14\n" +
	"\x05ready\x18\x02 \x01(\bR\x05ready\x12\x16\n" +
	"\x06device\x18\x03 \x01(\tR\x06device2\xc3\x02\n" +
	"\x12PromptGuardService\x12]\n" +
	"\bClassify\x12'.triage.prompt_guard.v1.ClassifyRequest\x1a(.triage.prompt_guard.v1.ClassifyResponse\x12l\n" +
	"\rClassifyBatch\x12,.triage.prompt_guard.v1.ClassifyBatchRequest\x1a-.triage.prompt_guard.v1.ClassifyBatchResponse\x12`\n" +
	"\tModelInfo\x12(.triage.prompt_guard.v1.ModelInfoRequest\x1a).triage.prompt_guard.v1.ModelInfoResponseBAZ?github.com/triage-ai/palisade/gen/prompt_guard/v1;promptguardv1b\x06proto3"

var (
	file_prompt_guard_v1_prompt_guard_proto_rawDescOnce sync.Once
	file_prompt_guard_v1_prompt_guard_proto_rawDescData []byte
)

func file_prompt_guard_v1_prompt_guard_proto_rawDescGZIP() []byte {
	file_prompt_guard_v1_prompt_guard_proto_rawDescOnce.Do(func() {
		file_prompt_guard_v1_prompt_guard_proto_rawDescData = protoimpl.X.CompressGZIP(unsafe.Slice(unsafe.StringData(file_prompt_guard_v1_prompt_guard_proto_rawDesc), len(file_prompt_guard_v1_prompt_guard_proto_rawDesc)))
	})
	return file_prompt_guard_v1_prompt_guard_proto_rawDescData
}

var file_prompt_guard_v1_prompt_guard_proto_msgTypes = make([]protoimpl.MessageInfo, 6)
var file_prompt_guard_v1_prompt_guard_proto_goTypes = []any{
	(*ClassifyRequest)(nil),       // 0: triage.prompt_guard.v1.ClassifyRequest
	(*ClassifyResponse)(nil),      // 1: triage.prompt_guard.v1.ClassifyResponse
	(*ClassifyBatchRequest)(nil),  // 2: triage.prompt_guard.v1.ClassifyBatchRequest
	(*ClassifyBatchResponse)(nil), // 3: triage.prompt_guard.v1.ClassifyBatchResponse
	(*ModelInfoRequest)(nil),      // 4: triage.prompt_guard.v1.ModelInfoRequest
	(*ModelInfoResponse)(nil),     // 5: triage.prompt_guard.v1.ModelInfoResponse
}
var file_prompt_guard_v1_prompt_guard_proto_depIdxs = []int32{
	1, // 0: triage.prompt_guard.v1.ClassifyBatchResponse.results:type_name -> triage.prompt_guard.v1.ClassifyResponse
	0, // 1: triage.prompt_guard.v1.PromptGuardService.Classify:input_type -> triage.prompt_guard.v1.ClassifyRequest
	2, // 2: triage.prompt_guard.v1.PromptGuardService.ClassifyBatch:input_type -> triage.prompt_guard.v1.ClassifyBatchRequest
	4, // 3: triage.prompt_guard.v1.PromptGuardService.ModelInfo:input_type -> triage.prompt_guard.v1.ModelInfoRequest
	1, // 4: triage.prompt_guard.v1.PromptGuardService.Classify:output_type -> triage.prompt_guard.v1.ClassifyResponse
	3, // 5: triage.prompt_guard.v1.PromptGuardService.ClassifyBatch:output_type -> triage.prompt_guard.v1.ClassifyBatchResponse
	5, // 6: triage.prompt_guard.v1.PromptGuardService.ModelInfo:output_type -> triage.prompt_guard.v1.ModelInfoResponse
	4, // [4:7] is the sub-list for method output_type
	1, // [1:4] is the sub-list for method input_type
	1, // [1:1] is the sub-list for extension type_name
	1, // [1:1] is the sub-list for extension extendee
	0, // [0:1] is the sub-list for field type_name
}

func init() { file_prompt_guard_v1_prompt_guard_proto_init() }
func file_prompt_guard_v1_prompt_guard_proto_init() {
	if File_prompt_guard_v1_prompt_guard_proto != nil {
		return
	}
	type x struct{}
	out := protoimpl.TypeBuilder{
		File: protoimpl.DescBuilder{
			GoPackagePath: reflect.TypeOf(x{}).PkgPath(),
			RawDescriptor: unsafe.Slice(unsafe.StringData(file_prompt_guard_v1_prompt_guard_proto_rawDesc), len(file_prompt_guard_v1_prompt_guard_proto_rawDesc)),
			NumEnums:      0,
			NumMessages:   6,
			NumExtensions: 0,
			NumServices:   1,
		},
		GoTypes:           file_prompt_guard_v1_prompt_guard_proto_goTypes,
		DependencyIndexes: file_prompt_guard_v1_prompt_guard_proto_depIdxs,
		MessageInfos:      file_prompt_guard_v1_prompt_guard_proto_msgTypes,
	}.Build()
	File_prompt_guard_v1_prompt_guard_proto = out.File
	file_prompt_guard_v1_prompt_guard_proto_goTypes = nil
	file_prompt_guard_v1_prompt_guard_proto_depIdxs = nil
}
